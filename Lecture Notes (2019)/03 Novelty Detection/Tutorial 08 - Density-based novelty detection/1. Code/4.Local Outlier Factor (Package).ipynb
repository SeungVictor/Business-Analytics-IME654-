{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 5, 'instance': [5.4, 3.9], 'lof': 1.7772900227621489},\n",
       " {'index': 8, 'instance': [4.4, 2.9], 'lof': 1.2303691845059221},\n",
       " {'index': 0, 'instance': [5.1, 3.5], 'lof': 1.2204923267196601},\n",
       " {'index': 4, 'instance': [5, 3.6], 'lof': 1.0884383067188306},\n",
       " {'index': 7, 'instance': [5, 3.4], 'lof': 1.0382079371308102}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import warnings\n",
    "\n",
    "def distance_euclidean(instance1, instance2):\n",
    "    \"\"\"Computes the distance between two instances. Instances should be tuples of equal length.\n",
    "    Returns: Euclidean distance\n",
    "    Signature: ((attr_1_1, attr_1_2, ...), (attr_2_1, attr_2_2, ...)) -> float\"\"\"\n",
    "    def detect_value_type(attribute):\n",
    "        \"\"\"Detects the value type (number or non-number).\n",
    "        Returns: (value type, value casted as detected type)\n",
    "        Signature: value -> (str or float type, str or float value)\"\"\"\n",
    "        from numbers import Number\n",
    "        attribute_type = None\n",
    "        if isinstance(attribute, Number):\n",
    "            attribute_type = float\n",
    "            attribute = float(attribute)\n",
    "        else:\n",
    "            attribute_type = str\n",
    "            attribute = str(attribute)\n",
    "        return attribute_type, attribute\n",
    "    # check if instances are of same length\n",
    "    if len(instance1) != len(instance2):\n",
    "        raise AttributeError(\"Instances have different number of arguments.\")\n",
    "    # init differences vector\n",
    "    differences = [0] * len(instance1)\n",
    "    # compute difference for each attribute and store it to differences vector\n",
    "    for i, (attr1, attr2) in enumerate(zip(instance1, instance2)):\n",
    "        type1, attr1 = detect_value_type(attr1)\n",
    "        type2, attr2 = detect_value_type(attr2)\n",
    "        # raise error is attributes are not of same data type.\n",
    "        if type1 != type2:\n",
    "            raise AttributeError(\"Instances have different data types.\")\n",
    "        if type1 is float:\n",
    "            # compute difference for float\n",
    "            differences[i] = attr1 - attr2\n",
    "        else:\n",
    "            # compute difference for string\n",
    "            if attr1 == attr2:\n",
    "                differences[i] = 0\n",
    "            else:\n",
    "                differences[i] = 1\n",
    "    # compute RMSE (root mean squared error)\n",
    "    rmse = (sum(map(lambda x: x**2, differences)) / len(differences))**0.5\n",
    "    return rmse\n",
    "\n",
    "class LOF:\n",
    "    \"\"\"Helper class for performing LOF computations and instances normalization.\"\"\"\n",
    "    def __init__(self, instances, normalize=True, distance_function=distance_euclidean):\n",
    "        self.instances = instances\n",
    "        self.normalize = normalize\n",
    "        self.distance_function = distance_function\n",
    "        if normalize:\n",
    "            self.normalize_instances()\n",
    "\n",
    "    def compute_instance_attribute_bounds(self):\n",
    "        min_values = [float(\"inf\")] * len(self.instances[0]) #n.ones(len(self.instances[0])) * n.inf\n",
    "        max_values = [float(\"-inf\")] * len(self.instances[0]) #n.ones(len(self.instances[0])) * -1 * n.inf\n",
    "        for instance in self.instances:\n",
    "            min_values = tuple(map(lambda x,y: min(x,y), min_values,instance)) #n.minimum(min_values, instance)\n",
    "            max_values = tuple(map(lambda x,y: max(x,y), max_values,instance)) #n.maximum(max_values, instance)\n",
    "\n",
    "        diff = [dim_max - dim_min for dim_max, dim_min in zip(max_values, min_values)]\n",
    "        if not all(diff):\n",
    "            problematic_dimensions = \", \".join(str(i+1) for i, v in enumerate(diff) if v == 0)\n",
    "            warnings.warn(\"No data variation in dimensions: %s. You should check your data or disable normalization.\" % problematic_dimensions)\n",
    "\n",
    "        self.max_attribute_values = max_values\n",
    "        self.min_attribute_values = min_values\n",
    "\n",
    "    def normalize_instances(self):\n",
    "        \"\"\"Normalizes the instances and stores the infromation for rescaling new instances.\"\"\"\n",
    "        if not hasattr(self, \"max_attribute_values\"):\n",
    "            self.compute_instance_attribute_bounds()\n",
    "        new_instances = []\n",
    "        for instance in self.instances:\n",
    "            new_instances.append(self.normalize_instance(instance)) # (instance - min_values) / (max_values - min_values)\n",
    "        self.instances = new_instances\n",
    "\n",
    "    def normalize_instance(self, instance):\n",
    "        return tuple(map(lambda value,max,min: (value-min)/(max-min) if max-min > 0 else 0,\n",
    "                         instance, self.max_attribute_values, self.min_attribute_values))\n",
    "\n",
    "    def local_outlier_factor(self, min_pts, instance):\n",
    "        \"\"\"The (local) outlier factor of instance captures the degree to which we call instance an outlier.\n",
    "        min_pts is a parameter that is specifying a minimum number of instances to consider for computing LOF value.\n",
    "        Returns: local outlier factor\n",
    "        Signature: (int, (attr1, attr2, ...), ((attr_1_1, ...),(attr_2_1, ...), ...)) -> float\"\"\"\n",
    "        if self.normalize:\n",
    "            instance = self.normalize_instance(instance)\n",
    "        return local_outlier_factor(min_pts, instance, self.instances, distance_function=self.distance_function)\n",
    "\n",
    "def k_distance(k, instance, instances, distance_function=distance_euclidean):\n",
    "    #TODO: implement caching\n",
    "    \"\"\"Computes the k-distance of instance as defined in paper. It also gatheres the set of k-distance neighbours.\n",
    "    Returns: (k-distance, k-distance neighbours)\n",
    "    Signature: (int, (attr1, attr2, ...), ((attr_1_1, ...),(attr_2_1, ...), ...)) -> (float, ((attr_j_1, ...),(attr_k_1, ...), ...))\"\"\"\n",
    "    distances = {}\n",
    "    for instance2 in instances:\n",
    "        distance_value = distance_function(instance, instance2)\n",
    "        if distance_value in distances:\n",
    "            distances[distance_value].append(instance2)\n",
    "        else:\n",
    "            distances[distance_value] = [instance2]\n",
    "    distances = sorted(distances.items())\n",
    "    neighbours = []\n",
    "    [neighbours.extend(n[1]) for n in distances[:k]]\n",
    "    k_distance_value = distances[k - 1][0] if len(distances) >= k else distances[-1][0]\n",
    "    return k_distance_value, neighbours\n",
    "\n",
    "def reachability_distance(k, instance1, instance2, instances, distance_function=distance_euclidean):\n",
    "    \"\"\"The reachability distance of instance1 with respect to instance2.\n",
    "    Returns: reachability distance\n",
    "    Signature: (int, (attr_1_1, ...),(attr_2_1, ...)) -> float\"\"\"\n",
    "    (k_distance_value, neighbours) = k_distance(k, instance2, instances, distance_function=distance_function)\n",
    "    return max([k_distance_value, distance_function(instance1, instance2)])\n",
    "\n",
    "def local_reachability_density(min_pts, instance, instances, **kwargs):\n",
    "    \"\"\"Local reachability density of instance is the inverse of the average reachability\n",
    "    distance based on the min_pts-nearest neighbors of instance.\n",
    "    Returns: local reachability density\n",
    "    Signature: (int, (attr1, attr2, ...), ((attr_1_1, ...),(attr_2_1, ...), ...)) -> float\"\"\"\n",
    "    (k_distance_value, neighbours) = k_distance(min_pts, instance, instances, **kwargs)\n",
    "    reachability_distances_array = [0]*len(neighbours) #n.zeros(len(neighbours))\n",
    "    for i, neighbour in enumerate(neighbours):\n",
    "        reachability_distances_array[i] = reachability_distance(min_pts, instance, neighbour, instances, **kwargs)\n",
    "    if not any(reachability_distances_array):\n",
    "        warnings.warn(\"Instance %s (could be normalized) is identical to all the neighbors. Setting local reachability density to inf.\" % repr(instance))\n",
    "        return float(\"inf\")\n",
    "    else:\n",
    "        return len(neighbours) / sum(reachability_distances_array)\n",
    "\n",
    "def local_outlier_factor(min_pts, instance, instances, **kwargs):\n",
    "    \"\"\"The (local) outlier factor of instance captures the degree to which we call instance an outlier.\n",
    "    min_pts is a parameter that is specifying a minimum number of instances to consider for computing LOF value.\n",
    "    Returns: local outlier factor\n",
    "    Signature: (int, (attr1, attr2, ...), ((attr_1_1, ...),(attr_2_1, ...), ...)) -> float\"\"\"\n",
    "    (k_distance_value, neighbours) = k_distance(min_pts, instance, instances, **kwargs)\n",
    "    instance_lrd = local_reachability_density(min_pts, instance, instances, **kwargs)\n",
    "    lrd_ratios_array = [0]* len(neighbours)\n",
    "    for i, neighbour in enumerate(neighbours):\n",
    "        instances_without_instance = set(instances)\n",
    "        instances_without_instance.discard(neighbour)\n",
    "        neighbour_lrd = local_reachability_density(min_pts, neighbour, instances_without_instance, **kwargs)\n",
    "        lrd_ratios_array[i] = neighbour_lrd / instance_lrd\n",
    "    return sum(lrd_ratios_array) / len(neighbours)\n",
    "\n",
    "def outliers(k, instances, **kwargs):\n",
    "    \"\"\"Simple procedure to identify outliers in the dataset.\"\"\"\n",
    "    instances_value_backup = instances\n",
    "    outliers = []\n",
    "    for i, instance in enumerate(instances_value_backup):\n",
    "        instances = list(instances_value_backup)\n",
    "        instances.remove(instance)\n",
    "        l = LOF(instances, **kwargs)\n",
    "        value = l.local_outlier_factor(k, instance)\n",
    "        if value > 1:\n",
    "            outliers.append({\"lof\": value, \"instance\": instance, \"index\": i})\n",
    "    outliers.sort(key=lambda o: o[\"lof\"], reverse=True)\n",
    "    return outliers\n",
    "\n",
    "\n",
    "data = [[5.1, 3.5], [4.9, 3], [4.7, 3.2], [4.6, 3.1], [5, 3.6], [5.4, 3.9], [4.6, 3.4], [5, 3.4], [4.4, 2.9], [4.9, 3.1]]\n",
    "outliers(3, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
